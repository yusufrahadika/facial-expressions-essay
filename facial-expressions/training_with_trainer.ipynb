{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -d \"fmix\" ] && git clone https://github.com/ecs-vlc/fmix\n",
    "![ ! -d \"adai\" ] && git clone https://github.com/zeke-xie/adaptive-inertia-adai adai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from adai.adai_optim import *\n",
    "from dataset.affectnet import AffectNetDataset\n",
    "from dataset.facialexpressions import FacialExpressionsDataset\n",
    "from dataset.ferplus import FERPlusDataset\n",
    "from dataset.rafdb import RAFDataset\n",
    "from fmix_weight import FMix\n",
    "from imgaug import augmenters as iaa\n",
    "from mish_cuda import MishCuda\n",
    "from model.ab import AccuracyBoosterPlusBlock\n",
    "from model.resnet import custom_resnet18, custom_resnet50, custom_resnet101\n",
    "from model.se import SqueezeExcitationBlock\n",
    "from optim.lookahead import Lookahead\n",
    "from optim.lr_scheduler.FlatCosineAnnealing import FlatCosineAnnealing\n",
    "from optim.radam import RAdam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (\n",
    "    ConcatDataset,\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    WeightedRandomSampler,\n",
    "    random_split,\n",
    ")\n",
    "from torchvision import models, transforms\n",
    "from tqdm.auto import tqdm, trange\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "torch.set_deterministic(True)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"facial-expressions-essay-v4\"\n",
    "\n",
    "WORKERS = cpu_count()\n",
    "\n",
    "BATCH_TARGET = 256\n",
    "BATCH_SIZE = 64\n",
    "GRAD_ACC = BATCH_TARGET // BATCH_SIZE\n",
    "\n",
    "MAX_STEP = 60_000\n",
    "INFERENCE_BATCH_SIZE = BATCH_SIZE // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Resize(256)\n",
    "centercrop_transform = transforms.CenterCrop(224)\n",
    "tensor_transform = transforms.ToTensor()\n",
    "normalize_transform = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        resize_transform,\n",
    "        centercrop_transform,\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.25, contrast=0.25, hue=0.05, saturation=0.05\n",
    "        ),\n",
    "        np.asarray,\n",
    "        iaa.Sequential(\n",
    "            [\n",
    "                iaa.Affine(rotate=(-15, 15), shear=(-15, 15), mode=\"symmetric\"),\n",
    "            ]\n",
    "        ).augment_image,\n",
    "        tensor_transform,\n",
    "        normalize_transform,\n",
    "    ]\n",
    ")\n",
    "\n",
    "predict_transform = transforms.Compose(\n",
    "    [resize_transform, centercrop_transform, tensor_transform, normalize_transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = ConcatDataset(\n",
    "    [\n",
    "        AffectNetDataset(\"../dataset/AffectNet\", \"train\", transform=train_transform),\n",
    "        FacialExpressionsDataset(\n",
    "            \"../dataset/facial_expressions\", transform=train_transform\n",
    "        ),\n",
    "        FERPlusDataset(\"../dataset/FERPlus\", \"train\", transform=train_transform),\n",
    "        RAFDataset(\"../dataset/RAF-DB\", \"train\", transform=train_transform),\n",
    "    ]\n",
    ")\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral', 'happy', 'surprise', 'sad', 'anger', 'disgust', 'fear', 'contempt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\n",
    "    \"neutral\",\n",
    "    \"happy\",\n",
    "    \"surprise\",\n",
    "    \"sad\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"contempt\",\n",
    "]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 94645, 152606,  19305,  31289,  28417,   4919,   7389,   3927])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [label for innerset in trainset.datasets for label in innerset.get_labels()]\n",
    "class_sample_count = np.unique(target, return_counts=True)[1]\n",
    "class_sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1 - (x / sum(class_sample_count)) for x in class_sample_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1.0 / class_sample_count\n",
    "# samples_weight = weight[target]\n",
    "# samples_weight = torch.from_numpy(samples_weight)\n",
    "# sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0566e-05, 6.5528e-06, 5.1800e-05, 3.1960e-05, 3.5190e-05, 2.0329e-04,\n",
       "        1.3534e-04, 2.5465e-04], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_weight = torch.as_tensor(weight, dtype=torch.float, device=device)\n",
    "tensor_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=WORKERS,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_dataset(dataset, n=5):\n",
    "#     pil_transform = transforms.ToPILImage()\n",
    "#     img = np.vstack(\n",
    "#         [\n",
    "#             np.hstack([pil_transform(dataset[i][0]) for _ in range(5)])\n",
    "#             for i in [random.randint(0, len(dataset)) for _ in range(n)]\n",
    "#         ]\n",
    "#     )\n",
    "#     plt.imshow(img)\n",
    "\n",
    "\n",
    "# show_dataset(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectnet_valset = AffectNetDataset(\n",
    "    \"../dataset/AffectNet\", \"val\", transform=predict_transform\n",
    ")\n",
    "ferplus_valset = FERPlusDataset(\n",
    "    \"../dataset/FERPlus\", \"val\", transform=predict_transform\n",
    ")\n",
    "ferplus_testset = FERPlusDataset(\n",
    "    \"../dataset/FERPlus\", \"test\", transform=predict_transform\n",
    ")\n",
    "raf_testset = RAFDataset(\"../dataset/RAF-DB\", \"test\", transform=predict_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7084, 7084)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valtestset = ConcatDataset(\n",
    "    [\n",
    "        affectnet_valset,\n",
    "        ferplus_valset,\n",
    "        ferplus_testset,\n",
    "        raf_testset,\n",
    "    ]\n",
    ")\n",
    "valsize = len(valtestset) // 2\n",
    "valset, testset = random_split(valtestset, [valsize, len(valtestset) - valsize])\n",
    "\n",
    "valloader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectnet_valloader = DataLoader(\n",
    "    affectnet_valset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "ferplus_valloader = DataLoader(\n",
    "    ferplus_valset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "ferplus_testloader = DataLoader(\n",
    "    ferplus_testset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "raf_testloader = DataLoader(\n",
    "    raf_testset,\n",
    "    batch_size=INFERENCE_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hub.list('zhanghang1989/ResNeSt', force_reload=False)\n",
    "# model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_resnet50(\n",
    "    activation_layer=MishCuda(),\n",
    "    #     network_type=\"pyramid\",\n",
    "    output_block={\n",
    "        \"class\": AccuracyBoosterPlusBlock,\n",
    "        \"params\": {},\n",
    "    },\n",
    "    #     zero_init_residual=True,\n",
    "    #     dropblock={\"drop_prob\": 0.1, \"max_steps\": MAX_STEP},\n",
    "    num_classes=len(classes),\n",
    "    without_skip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# fmix = FMix(size=(224, 224))\n",
    "criterion = nn.CrossEntropyLoss(weight=tensor_weight)\n",
    "fmix = FMix(size=(224, 224), weight=tensor_weight)\n",
    "\n",
    "\n",
    "def transform_func(X, y):\n",
    "    return fmix(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000, 20000, 30000, 40000, 50000, 60000]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i * 10_000 for i in range(1, (MAX_STEP // 10_000) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAdam optimizer loaded. \n",
      "Gradient Centralization usage = True \n",
      "Diffgrad usage = False\n",
      "Adabelief usage = False\n",
      "GC applied to both conv and fc layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myusufrahadika\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.14 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glamorous-star-139</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/yusufrahadika/facial-expressions-essay-v4\" target=\"_blank\">https://wandb.ai/yusufrahadika/facial-expressions-essay-v4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/yusufrahadika/facial-expressions-essay-v4/runs/1sj6uk15\" target=\"_blank\">https://wandb.ai/yusufrahadika/facial-expressions-essay-v4/runs/1sj6uk15</a><br/>\n",
       "                Run data is saved locally in <code>/run/media/yusufrahadika/WORKSPACEv2/facial-expressions-essay/facial-expressions/wandb/run-20210118_123817-1sj6uk15</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: output/glamorous-star-139\n"
     ]
    }
   ],
   "source": [
    "optimizer = RAdam(model.parameters(), lr=1e-3, diffgrad=False)\n",
    "optimizer = Lookahead(optimizer)\n",
    "scheduler = FlatCosineAnnealing(optimizer, MAX_STEP, step_size=0.5)\n",
    "\n",
    "# optimizer = Adai(model.parameters(), lr=1e-2)\n",
    "# scheduler = FlatCosineAnnealing(optimizer, MAX_STEP, step_size=0.5)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer,\n",
    "#     milestones=[i * 10_000 for i in range(1, (MAX_STEP // 10_000) + 1)],\n",
    "#     gamma=0.75,\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    PROJECT_NAME,\n",
    "    model,\n",
    "    device,\n",
    "    trainloader,\n",
    "    classes,\n",
    "    criterion=fmix.loss,\n",
    "    valloaders=[\n",
    "        (\"mixed\", valloader),\n",
    "        (\"affectnet\", affectnet_valloader),\n",
    "        (\"ferplus\", ferplus_valloader),\n",
    "    ],\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    gradient_accumulation=GRAD_ACC,\n",
    "    lr_find=False,\n",
    "    max_step=MAX_STEP,\n",
    "    transform_func=transform_func,\n",
    "    val_criterion=nn.CrossEntropyLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6618a7f3d74d4d9151561b66fd029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                         str |      161485 |     28.86 MB\n",
      "                        dict |       54466 |     22.00 MB\n",
      "                         int |      371403 |      9.96 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        list |       11916 |      7.20 MB\n",
      "                        type |        8119 |      7.17 MB\n",
      "                       tuple |       50857 |      3.85 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       10988 |    944.28 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        7781 |    607.89 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff71885abd624493bcdea89549d44759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                         str |      193048 |     31.14 MB\n",
      "                        dict |       54810 |     22.23 MB\n",
      "                        list |       41845 |     20.18 MB\n",
      "                         int |      720510 |     19.28 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       50948 |      3.86 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11047 |    949.35 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        7877 |    615.39 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6599343286a4d759826a48c7ba1aae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                        list |       71773 |     36.28 MB\n",
      "                         str |      222923 |     33.27 MB\n",
      "                         int |     1069700 |     28.61 MB\n",
      "                        dict |       55234 |     22.34 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       51035 |      3.86 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11091 |    953.13 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        7971 |    622.73 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388e185120b14ea3a1b4bf95b38d3f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                        list |      101703 |     55.16 MB\n",
      "                         int |     1418819 |     37.93 MB\n",
      "                         str |      252798 |     35.41 MB\n",
      "                        dict |       55587 |     22.43 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       51121 |      3.87 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11135 |    956.91 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        8065 |    630.08 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165b630d8ca493993856bdecdc5c386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                        list |      131635 |     77.58 MB\n",
      "                         int |     1767907 |     47.25 MB\n",
      "                         str |      282673 |     37.54 MB\n",
      "                        dict |       55909 |     22.51 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       51208 |      3.88 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11179 |    960.70 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        8159 |    637.42 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac26e6532d64833909ae5f381ca88ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                        list |      161569 |    104.46 MB\n",
      "                         int |     2117095 |     56.58 MB\n",
      "                         str |      312548 |     39.67 MB\n",
      "                        dict |       56328 |     22.60 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       51295 |      3.88 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11223 |    964.48 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        8253 |    644.77 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccf3099ed424e17a83e0e0a49f83996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cv2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "                        list |      191505 |    134.00 MB\n",
      "                         int |     2466211 |     65.90 MB\n",
      "                         str |      342423 |     41.81 MB\n",
      "                        dict |       56676 |     22.69 MB\n",
      "                        code |       52649 |      7.27 MB\n",
      "                        type |        8133 |      7.17 MB\n",
      "                       tuple |       51381 |      3.89 MB\n",
      "               numpy.ndarray |         167 |      2.74 MB\n",
      "                         set |        2508 |      1.18 MB\n",
      "                     weakref |       11267 |    968.26 KB\n",
      "     collections.OrderedDict |        2305 |    915.52 KB\n",
      "                 numpy.int64 |       28385 |    887.03 KB\n",
      "                 abc.ABCMeta |         636 |    656.74 KB\n",
      "           getset_descriptor |        8367 |    653.67 KB\n",
      "  builtin_function_or_method |        8347 |    652.11 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f69643a18454291a37e521c9071e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for i, (inputs, _) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.append(predicted)\n",
    "\n",
    "    return torch.cat(y_pred).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = wandb.run.name\n",
    "wandb.init(name=RUN_NAME, project=f\"{PROJECT_NAME}_test\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual = np.asarray([target for _, targets in testloader for target in targets])\n",
    "y_test_pred = predict(model, testloader, device)\n",
    "test_acc = accuracy_score(y_test_actual, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Test accuracy:\", test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferplus_y_test_actual = np.asarray(\n",
    "    [target for _, targets in ferplus_testloader for target in targets]\n",
    ")\n",
    "ferplus_y_test_pred = predict(model, ferplus_testloader, device)\n",
    "ferplus_test_acc = accuracy_score(ferplus_y_test_actual, ferplus_y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"FERPlus Test accuracy:\", ferplus_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raf_y_test_actual = np.asarray(\n",
    "    [target for _, targets in raf_testloader for target in targets]\n",
    ")\n",
    "raf_y_test_pred = predict(model, raf_testloader, device)\n",
    "raf_test_acc = accuracy_score(raf_y_test_actual, raf_y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"RAF-DB Test accuracy:\", raf_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(\n",
    "    {\n",
    "        \"mixed_test_acc\": test_acc,\n",
    "        \"ferplus_test_acc\": ferplus_test_acc,\n",
    "        \"raf_test_acc\": raf_test_acc,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}